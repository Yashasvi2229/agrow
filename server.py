import os
import sys
import logging
import threading
from pathlib import Path
from flask import Flask, request, jsonify
from twilio.twiml.voice_response import VoiceResponse, Gather, Redirect
from twilio.request_validator import RequestValidator
import requests
from dotenv import load_dotenv

# Import conversation state management
from conversation_state import conversations, create_session, get_session, end_session

# Add ai-helpline-pipeline to Python path
sys.path.insert(0, str(Path(__file__).parent / "ai-helpline-pipeline"))

# Import the existing pipeline
from pipeline import HelplinePipeline
from config import load_config

# Import WhatsApp client for sending summaries
sys.path.insert(0, str(Path(__file__).parent / "ai-helpline-pipeline" / "api_clients"))
from whatsapp_client import send_summary_via_whatsapp

# Load environment variables
load_dotenv()

# Initialize Flask app
app = Flask(__name__)

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize pipeline
try:
    config = load_config()
    pipeline = HelplinePipeline(config=config, logger=logger)
    logger.info("Pipeline initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize pipeline: {e}")
    pipeline = None

# Twilio configuration
TWILIO_ACCOUNT_SID = os.getenv("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.getenv("TWILIO_AUTH_TOKEN")
TWILIO_PHONE_NUMBER = os.getenv("TWILIO_PHONE_NUMBER")

# Create directories
TEMP_DIR = Path("temp_uploads")
OUTPUT_DIR = Path("output_audio")
TEMP_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# In-memory storage for call language preferences
# In production, use Redis or database
call_language_map = {}

# Storage for Twilio's SpeechResult (better quality than ElevenLabs for follow-ups)
twilio_transcriptions = {}

# India STD code ‚Üí Language mapping for phone-based language detection
# Maps area codes to primary languages spoken in those regions
STD_TO_LANGUAGE = {
    # Hindi belt (North India)
    "11": "hi",    # Delhi
    "120": "hi",   # Noida
    "121": "hi",   # Faridabad
    "124": "hi",   # Gurgaon
    "141": "hi",   # Jaipur
    "145": "hi",   # Ajmer
    "161": "hi",   # Ludhiana
    "172": "pa",   # Chandigarh (Punjabi)
    "181": "pa",   # Jammu
    "191": "hi",   # UP - Meerut
    "522": "hi",   # Lucknow
    "512": "hi",   # Kanpur
    "542": "hi",   # Varanasi
    "562": "hi",   # Agra
    "571": "hi",   # Aligarh
    "612": "hi",   # Patna
    "651": "hi",   # Ranchi
    
    # Marathi (Maharashtra)
    "22": "mr",    # Mumbai
    "20": "mr",    # Pune
    "212": "mr",   # Aurangabad
    "231": "mr",   # Nagpur
    "251": "mr",   # Nashik
    
    # Tamil (Tamil Nadu)
    "44": "ta",    # Chennai
    "422": "ta",   # Coimbatore
    "427": "ta",   # Salem
    "452": "ta",   # Madurai
    "462": "ta",   # Tiruchirapalli
    
    # Telugu (Telangana & Andhra Pradesh) 
    "40": "te",    # Hyderabad
    "863": "te",   # Vijayawada
    "891": "te",   # Visakhapatnam
    "866": "te",   # Guntur
    
    # Kannada (Karnataka)
    "80": "kn",    # Bangalore
    "821": "kn",   # Mysore
    "824": "kn",   # Mangalore
    "836": "kn",   # Belgaum
    
    # Bengali (West Bengal)
    "33": "bn",    # Kolkata
    "341": "bn",   # Siliguri
    "353": "bn",   # Durgapur
    
    # Gujarati (Gujarat)
    "79": "gu",    # Ahmedabad
    "261": "gu",   # Surat
    "265": "gu",   # Vadodara
    "281": "gu",   # Rajkot
}

# Multi-language prompts for TwiML messages
LANGUAGE_PROMPTS = {
    "hi": {  # Hindi
        "welcome": "‡§è‡§ó‡•ç‡§∞‡•ã‡§µ‡§æ‡§á‡§ú‡§º ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è AI-‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ï‡•É‡§∑‡§ø ‡§π‡•á‡§≤‡•ç‡§™‡§≤‡§æ‡§á‡§® ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¨‡•Ä‡§™ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§",
        "processing": "‡§Ü‡§™‡§ï‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç‡•§",
        "still_processing": "‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§∞‡•Ä ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•à‡§∞‡•ç‡§Ø ‡§∞‡§ñ‡•á‡§Ç‡•§",
        "thank_you": "‡§è‡§ó‡•ç‡§∞‡•ã‡§µ‡§æ‡§á‡§ú‡§º ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§¶‡§ø‡§® ‡§π‡•ã!",
        "error": "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Ü‡§™‡§ï‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•Å‡§à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§",
        "another_question": "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡§æ ‡§ï‡•ã‡§à ‡§î‡§∞ ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à?",
        "still_there": "‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§µ‡§π‡§æ‡§Å ‡§π‡•à‡§Ç? ‡§ï‡•ã‡§à ‡§î‡§∞ ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à?"
    },
    "ta": {  # Tamil
        "welcome": "‡ÆÖ‡Æï‡Øç‡Æ∞‡Øã‡Æµ‡Øà‡Æ∏‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æµ‡Æ∞‡Æµ‡Øá‡Æ±‡Øç‡Æï‡Æø‡Æ±‡Øã‡ÆÆ‡Øç. ‡Æá‡Æ§‡ØÅ ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ‡Æø‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡Ææ‡Æ© AI-‡Æá‡ÆØ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Øá‡Æ≥‡Ææ‡Æ£‡Øç ‡Æâ‡Æ§‡Æµ‡Æø ‡Æé‡Æ£‡Øç. ‡Æ™‡ØÄ‡Æ™‡Øç ‡Æí‡Æ≤‡Æø‡Æï‡Øç‡Æï‡ØÅ‡Æ™‡Øç ‡Æ™‡Æø‡Æ±‡Æï‡ØÅ ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡ÆØ‡Øà ‡Æé‡Æ®‡Øç‡Æ§ ‡Æá‡Æ®‡Øç‡Æ§‡Æø‡ÆØ ‡ÆÆ‡Øä‡Æ¥‡Æø‡ÆØ‡Æø‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æï‡Øá‡Æü‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.",
        "processing": "‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Ææ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡Æï‡Ææ‡Æ§‡Øç‡Æ§‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.",
        "still_processing": "‡Æá‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Ææ‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æ§‡Øä‡Æü‡Æ∞‡Øç‡Æï‡Æø‡Æ±‡Æ§‡ØÅ. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡Æ™‡Øä‡Æ±‡ØÅ‡ÆÆ‡Øà‡ÆØ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç.",
        "thank_you": "‡ÆÖ‡Æï‡Øç‡Æ∞‡Øã‡Æµ‡Øà‡Æ∏‡Øà‡Æ™‡Øç ‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æø‡ÆØ‡Æ§‡Æ±‡Øç‡Æï‡ØÅ ‡Æ®‡Æ©‡Øç‡Æ±‡Æø. ‡Æ®‡Æ≤‡Øç‡Æ≤ ‡Æ®‡Ææ‡Æ≥‡Øç!",
        "error": "‡ÆÆ‡Æ©‡Øç‡Æ©‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç, ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡ÆØ‡Øà ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Ææ‡Æï‡Øç‡Æï‡ØÅ‡Æµ‡Æ§‡Æø‡Æ≤‡Øç ‡Æ™‡Æø‡Æ¥‡Øà ‡Æè‡Æ±‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡ØÅ. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.",
        "another_question": "‡Æµ‡Øá‡Æ±‡ØÅ ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡Ææ?",
        "still_there": "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æá‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Ææ? ‡Æµ‡Øá‡Æ±‡ØÅ ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡Ææ?"
    },
    "te": {  # Telugu
        "welcome": "‡∞Ü‡∞ó‡±ç‡∞∞‡±ã‡∞µ‡±à‡∞ú‡±ç‚Äå‡∞ï‡±Å ‡∞∏‡±ç‡∞µ‡∞æ‡∞ó‡∞§‡∞Ç. ‡∞á‡∞¶‡∞ø ‡∞∞‡±à‡∞§‡±Å‡∞≤ ‡∞ï‡±ã‡∞∏‡∞Ç AI-‡∞Ü‡∞ß‡∞æ‡∞∞‡∞ø‡∞§ ‡∞µ‡±ç‡∞Ø‡∞µ‡∞∏‡∞æ‡∞Ø ‡∞π‡±Ü‡∞≤‡±ç‡∞™‡±ç‚Äå‡∞≤‡±à‡∞®‡±ç. ‡∞¨‡±Ä‡∞™‡±ç ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞è ‡∞≠‡∞æ‡∞∞‡∞§‡±Ä‡∞Ø ‡∞≠‡∞æ‡∞∑‡∞≤‡±ã‡∞®‡±à‡∞®‡∞æ ‡∞Ö‡∞°‡∞ó‡∞Ç‡∞°‡∞ø.",
        "processing": "‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞Ö‡∞µ‡±Å‡∞§‡±ã‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞µ‡±á‡∞ö‡∞ø ‡∞â‡∞Ç‡∞°‡∞Ç‡∞°‡∞ø.",
        "still_processing": "‡∞á‡∞Ç‡∞ï‡∞æ ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ä‡∞®‡∞∏‡∞æ‡∞ó‡±Å‡∞§‡±ã‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞ì‡∞™‡∞ø‡∞ï ‡∞™‡∞ü‡±ç‡∞ü‡∞Ç‡∞°‡∞ø.",
        "thank_you": "‡∞Ü‡∞ó‡±ç‡∞∞‡±ã‡∞µ‡±à‡∞ú‡±ç ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å. ‡∞Æ‡∞Ç‡∞ö‡∞ø ‡∞∞‡±ã ‡∞ú‡±Å!",
        "error": "‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.",
        "another_question": "‡∞Æ‡∞∞‡±ã ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞â‡∞Ç‡∞¶‡∞æ?",
        "still_there": "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞á‡∞Ç‡∞ï‡∞æ ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ? ‡∞Æ‡∞∞‡±ã ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞â‡∞Ç‡∞¶‡∞æ?"
    },
    "kn": {  # Kannada
        "welcome": "‡≤Ü‡≤ó‡≥ç‡≤∞‡≥ã‡≤µ‡≥à‡≤∏‡≥ç‚Äå‡≤ó‡≥Ü ‡≤∏‡≥ç‡≤µ‡≤æ‡≤ó‡≤§. ‡≤á‡≤¶‡≥Å ‡≤∞‡≥à‡≤§‡≤∞‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø AI-‡≤ö‡≤æ‡≤≤‡≤ø‡≤§ ‡≤ï‡≥É‡≤∑‡≤ø ‡≤∏‡≤π‡≤æ‡≤Ø‡≤µ‡≤æ‡≤£‡≤ø. ‡≤¨‡≥Ä‡≤™‡≥ç ‡≤®‡≤Ç‡≤§‡≤∞ ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤≠‡≤æ‡≤∞‡≤§‡≥Ä‡≤Ø ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≥á‡≤≥‡≤ø.",
        "processing": "‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤¶‡≥Ü. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤®‡≤ø‡≤∞‡≥Ä‡≤ï‡≥ç‡≤∑‡≤ø‡≤∏‡≤ø.",
        "still_processing": "‡≤á‡≤®‡≥ç‡≤®‡≥Ç ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤§‡≤æ‡≤≥‡≥ç‡≤Æ‡≥Ü ‡≤á‡≤∞‡≤ø‡≤∏‡≤ø.",
        "thank_you": "‡≤Ü‡≤ó‡≥ç‡≤∞‡≥ã‡≤µ‡≥à‡≤∏‡≥ç ‡≤¨‡≤≥‡≤∏‡≤ø‡≤¶‡≥ç‡≤¶‡≤ï‡≥ç‡≤ï‡≤æ‡≤ó‡≤ø ‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å. ‡≤∂‡≥Å‡≤≠ ‡≤¶‡≤ø‡≤®!",
        "error": "‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≤≤‡≥ç‡≤≤‡≤ø ‡≤¶‡≥ã‡≤∑‡≤µ‡≤ø‡≤¶‡≥Ü. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥ä‡≤Æ‡≥ç‡≤Æ‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø.",
        "another_question": "‡≤¨‡≥á‡≤∞‡≥Ü ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤á‡≤¶‡≥Ü‡≤Ø‡≤æ?",
        "still_there": "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤á‡≤®‡≥ç‡≤®‡≥Ç ‡≤á‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤æ? ‡≤¨‡≥á‡≤∞‡≥Ü ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤á‡≤¶‡≥Ü‡≤Ø‡≤æ?"
    },
    "mr": {  # Marathi
        "welcome": "‡§è‡§ó‡•ç‡§∞‡•ã‡§µ‡§æ‡§à‡§ù‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Ü‡§™‡§≤‡•á ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§Ü‡§π‡•á. ‡§π‡•Ä ‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä AI-‡§ö‡§æ‡§≤‡§ø‡§§ ‡§ï‡•É‡§∑‡•Ä ‡§π‡•á‡§≤‡•ç‡§™‡§≤‡§æ‡§á‡§® ‡§Ü‡§π‡•á. ‡§¨‡•Ä‡§™ ‡§®‡§Ç‡§§‡§∞ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ü‡§™‡§≤‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ‡§π‡•Ä ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§≠‡§æ‡§∑‡•á‡§§ ‡§µ‡§ø‡§ö‡§æ‡§∞‡§æ.",
        "processing": "‡§Ü‡§™‡§≤‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§æ‡§µ‡§∞ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§§ ‡§Ü‡§π‡•á. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡§æ.",
        "still_processing": "‡§Ö‡§ú‡•Ç‡§®‡§π‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡•Å‡§∞‡•Ç ‡§Ü‡§π‡•á. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•Ä‡§∞ ‡§ß‡§∞‡§æ.",
        "thank_you": "‡§è‡§ó‡•ç‡§∞‡•ã‡§µ‡§æ‡§à‡§ù ‡§µ‡§æ‡§™‡§∞‡§≤‡•ç‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶. ‡§ö‡§æ‡§Ç‡§ó‡§≤‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§Ö‡§∏‡•ã!",
        "error": "‡§Æ‡§æ‡§´ ‡§ï‡§∞‡§æ, ‡§Ü‡§™‡§≤‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡§∞‡§§‡§æ‡§®‡§æ ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§Ü‡§≤‡•Ä. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ.",
        "another_question": "‡§Ü‡§£‡§ñ‡•Ä ‡§ï‡§æ‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§Ü‡§π‡•á ‡§ï‡§æ?",
        "still_there": "‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Ö‡§ú‡•Ç‡§® ‡§§‡§ø‡§•‡•á ‡§Ü‡§π‡§æ‡§§? ‡§Ü‡§£‡§ñ‡•Ä ‡§ï‡§æ‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§Ü‡§π‡•á ‡§ï‡§æ?"
    },
    "pa": {  # Punjabi
        "welcome": "‡®ê‡®ó‡®∞‡©ã‡®µ‡®æ‡®à‡®ú‡®º ‡®µ‡®ø‡©±‡®ö ‡®§‡©Å‡®π‡®æ‡®°‡®æ ‡®∏‡®µ‡®æ‡®ó‡®§ ‡®π‡©à‡•§ ‡®á‡®π ‡®ï‡®ø‡®∏‡®æ‡®®‡®æ‡®Ç ‡®≤‡®à AI-‡®∏‡©∞‡®ö‡®æ‡®≤‡®ø‡®§ ‡®ñ‡©á‡®§‡©Ä‡®¨‡®æ‡©ú‡©Ä ‡®π‡©à‡®≤‡®™‡®≤‡®æ‡®à‡®® ‡®π‡©à‡•§ ‡®¨‡©Ä‡®™ ‡®§‡©ã‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®Ü‡®™‡®£‡®æ ‡®∏‡®µ‡®æ‡®≤ ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®≠‡®æ‡®∞‡®§‡©Ä ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®™‡©Å‡©±‡®õ‡©ã‡•§",
        "processing": "‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®∏‡®µ‡®æ‡®≤ ‡®¶‡©Ä ‡®™‡©ç‡®∞‡®ï‡©ç‡®∞‡®ø‡®Ü ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ ‡®∞‡®π‡©Ä ‡®π‡©à‡•§ ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®â‡®°‡©Ä‡®ï ‡®ï‡®∞‡©ã‡•§",
        "still_processing": "‡®Ö‡®ú‡©á ‡®µ‡©Ä ‡®™‡©ç‡®∞‡®ï‡©ç‡®∞‡®ø‡®Ü ‡®ú‡®æ‡®∞‡©Ä ‡®π‡©à‡•§ ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®∏‡®¨‡®∞ ‡®ï‡®∞‡©ã‡•§",
        "thank_you": "‡®ê‡®ó‡®∞‡©ã‡®µ‡®æ‡®à‡®ú‡®º ‡®µ‡®∞‡®§‡®£ ‡®≤‡®à ‡®ß‡©∞‡®®‡®µ‡®æ‡®¶‡•§ ‡®ö‡©∞‡®ó‡®æ ‡®¶‡®ø‡®®!",
        "error": "‡®Æ‡®æ‡®´‡®º ‡®ï‡®∞‡®®‡®æ, ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®∏‡®µ‡®æ‡®≤ ‡®¶‡©Ä ‡®™‡©ç‡®∞‡®ï‡©ç‡®∞‡®ø‡®Ü ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä ‡®π‡©ã‡®à‡•§ ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ ‡®ï‡©ã‡®∏‡®º‡®ø‡®∏‡®º ‡®ï‡®∞‡©ã‡•§",
        "another_question": "‡®ï‡©Ä ‡®ï‡©ã‡®à ‡®π‡©ã‡®∞ ‡®∏‡®µ‡®æ‡®≤ ‡®π‡©à?",
        "still_there": "‡®ï‡©Ä ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®Ö‡®ú‡©á ‡®µ‡©Ä ‡®π‡©ã? ‡®ï‡©ã‡®à ‡®π‡©ã‡®∞ ‡®∏‡®µ‡®æ‡®≤ ‡®π‡©à?"
    },
    "bn": {  # Bengali
        "welcome": "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ó‡ßç‡¶∞‡ßã‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶ú-‡¶è ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶∏‡ßç‡¶¨‡¶æ‡¶ó‡¶§‡¶Æ‡•§ ‡¶è‡¶ü‡¶ø ‡¶ï‡ßÉ‡¶∑‡¶ï‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø AI-‡¶ö‡¶æ‡¶≤‡¶ø‡¶§ ‡¶ï‡ßÉ‡¶∑‡¶ø ‡¶π‡ßá‡¶≤‡ßç‡¶™‡¶≤‡¶æ‡¶á‡¶®‡•§ ‡¶¨‡¶ø‡¶™‡ßá‡¶∞ ‡¶™‡¶∞‡ßá ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶≠‡¶æ‡¶∞‡¶§‡ßÄ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
        "processing": "‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ß‡ßÄ‡¶®‡•§ ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
        "still_processing": "‡¶è‡¶ñ‡¶®‡¶ì ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ö‡¶≤‡¶õ‡ßá‡•§ ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶ß‡ßà‡¶∞‡ßç‡¶Ø ‡¶ß‡¶∞‡ßÅ‡¶®‡•§",
        "thank_you": "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ó‡ßç‡¶∞‡ßã‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶ú ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶‡•§ ‡¶∂‡ßÅ‡¶≠ ‡¶¶‡¶ø‡¶®!",
        "error": "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶¶‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡ßá ‡¶™‡ßÅ‡¶®‡¶∞‡¶æ‡¶Ø‡¶º ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
        "another_question": "‡¶Ü‡¶∞ ‡¶ï‡ßã‡¶®‡ßã ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ü‡¶õ‡ßá?",
        "still_there": "‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶è‡¶ñ‡¶®‡¶ì ‡¶Ü‡¶õ‡ßá‡¶®? ‡¶Ü‡¶∞ ‡¶ï‡ßã‡¶®‡ßã ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ü‡¶õ‡ßá?"
    },
    "gu": {  # Gujarati
        "welcome": "‡™è‡™ó‡´ç‡™∞‡´ã‡™µ‡™æ‡™á‡™ù‡™Æ‡™æ‡™Ç ‡™§‡™Æ‡™æ‡™∞‡´Å‡™Ç ‡™∏‡´ç‡™µ‡™æ‡™ó‡™§ ‡™õ‡´á. ‡™Ü ‡™ñ‡´á‡™°‡´Ç‡™§‡´ã ‡™Æ‡™æ‡™ü‡´á AI-‡™∏‡™Ç‡™ö‡™æ‡™≤‡™ø‡™§ ‡™ï‡´É‡™∑‡™ø ‡™π‡´á‡™≤‡´ç‡™™‡™≤‡™æ‡™á‡™® ‡™õ‡´á. ‡™¨‡´Ä‡™™ ‡™™‡™õ‡´Ä ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™ï‡´ã‡™à‡™™‡™£ ‡™≠‡™æ‡™∞‡™§‡´Ä‡™Ø ‡™≠‡™æ‡™∑‡™æ‡™Æ‡™æ‡™Ç ‡™§‡™Æ‡™æ‡™∞‡´ã ‡™™‡´ç‡™∞‡™∂‡´ç‡™® ‡™™‡´Ç‡™õ‡´ã.",
        "processing": "‡™§‡™Æ‡™æ‡™∞‡™æ ‡™™‡´ç‡™∞‡™∂‡´ç‡™®‡™®‡´Ä ‡™™‡´ç‡™∞‡™ï‡´ç‡™∞‡™ø‡™Ø‡™æ ‡™•‡™à ‡™∞‡™π‡´Ä ‡™õ‡´á. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™∞‡™æ‡™π ‡™ú‡´Å‡™ì.",
        "still_processing": "‡™π‡™ú‡´Å ‡™™‡™£ ‡™™‡´ç‡™∞‡™ï‡´ç‡™∞‡™ø‡™Ø‡™æ ‡™ö‡™æ‡™≤‡´Å ‡™õ‡´á. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™ß‡´Ä‡™∞‡™ú ‡™∞‡™æ‡™ñ‡´ã.",
        "thank_you": "‡™è‡™ó‡´ç‡™∞‡´ã‡™µ‡™æ‡™á‡™ù ‡™µ‡™æ‡™™‡™∞‡™µ‡™æ ‡™¨‡™¶‡™≤ ‡™Ü‡™≠‡™æ‡™∞. ‡™∏‡™æ‡™∞‡´ã ‡™¶‡™ø‡™µ‡™∏!",
        "error": "‡™Æ‡™æ‡™´ ‡™ï‡™∞‡™∂‡´ã, ‡™§‡™Æ‡™æ‡™∞‡™æ ‡™™‡´ç‡™∞‡™∂‡´ç‡™®‡™®‡´Ä ‡™™‡´ç‡™∞‡™ï‡´ç‡™∞‡™ø‡™Ø‡™æ‡™Æ‡™æ‡™Ç ‡™≠‡´Ç‡™≤ ‡™Ü‡™µ‡´Ä. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™´‡™∞‡´Ä ‡™™‡´ç‡™∞‡™Ø‡™æ‡™∏ ‡™ï‡™∞‡´ã.",
        "another_question": "‡™ï‡´ã‡™à ‡™Ö‡™®‡´ç‡™Ø ‡™™‡´ç‡™∞‡™∂‡´ç‡™® ‡™õ‡´á?",
        "still_there": "‡™§‡™Æ‡´á ‡™Ö‡™ú‡´á ‡™™‡™£ ‡™§‡´ç‡™Ø‡™æ‡™Ç ‡™õ‡´ã? ‡™ï‡´ã‡™à ‡™Ö‡™®‡´ç‡™Ø ‡™™‡´ç‡™∞‡™∂‡´ç‡™® ‡™õ‡´á?"
    },
    "en": {  # English (fallback)
        "welcome": "Welcome to AgroWise, the AI-powered agricultural helpline for farmers. Please ask your question in any Indian language after the beep.",
        "processing": "Processing your question. Please wait.",
        "still_processing": "Still processing. Please continue to hold.",
        "thank_you": "Thank you for using AgroWise. Have a great day!",
        "error": "Sorry, we encountered an error processing your question. Please try again.",
        "another_question": "Do you have another question?",
        "still_there": "Are you still there? Do you have another question?"
    }
}

def detect_language_from_phone(phone_number: str) -> str:
    """
    Detect language from Indian phone number based on STD code.
    
    Args:
        phone_number: Phone number in format +91XXXXXXXXXX
        
    Returns:
        Language code (hi, ta, te, etc.). Defaults to 'hi' if not found.
    """
    try:
        # Remove +91 country code
        if phone_number.startswith("+91"):
            phone_number = phone_number[3:]
        elif phone_number.startswith("91"):
            phone_number = phone_number[2:]
        
        # Try 3-digit STD code first
        std_code_3 = phone_number[:3]
        if std_code_3 in STD_TO_LANGUAGE:
            lang = STD_TO_LANGUAGE[std_code_3]
            logger.info(f"Detected language '{lang}' from STD code {std_code_3}")
            return lang
        
        # Try 2-digit STD code
        std_code_2 = phone_number[:2]
        if std_code_2 in STD_TO_LANGUAGE:
            lang = STD_TO_LANGUAGE[std_code_2]
            logger.info(f"Detected language '{lang}' from STD code {std_code_2}")
            return lang
        
        # Default to Hindi if no match
        logger.info(f"No STD code match for {phone_number[:4]}, defaulting to Hindi")
        return "hi"
        
    except Exception as e:
        logger.error(f"Error detecting language from phone: {e}")
        return "hi"  # Safe fallback


def get_twilio_lang(detected_lang: str) -> str:
    """
    Map our language codes to Twilio-compatible language codes with voice preferences.
    
    Args:
        detected_lang: Our internal language code (hi, ta, te, etc.)
        
    Returns:
        Twilio language code (e.g., 'hi-IN', 'ta-IN')
    """
    twilio_lang_map = {
        "hi": "hi-IN",
        "ta": "ta-IN",
        "te": "te-IN",
        "kn": "kn-IN",
        "mr": "mr-IN",
        "pa": "pa-IN",
        "bn": "bn-IN",
        "gu": "gu-IN",
        "ml": "ml-IN",
        "en": "en-IN"
    }
    return twilio_lang_map.get(detected_lang, "hi-IN")


def check_exit_intent(speech_result: str, digits: str, detected_lang: str) -> bool:
    """
    Check if user wants to exit the conversation.
    
    Args:
        speech_result: Transcribed speech from user
        digits: DTMF digits pressed
        detected_lang: Current conversation language
        
    Returns:
        True if user wants to exit
    """
    # Exit keywords by language
    exit_keywords = {
        'en': ['bye', 'goodbye', 'thank you', 'thanks', 'no more', 'exit', 'end', 'hangup', 'hang up'],
        'hi': ['‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ', '‡§®‡§π‡•Ä‡§Ç', '‡§¨‡§∏', '‡§†‡•Ä‡§ï ‡§π‡•à', '‡§∞‡•Å‡§ï‡•ã'],
        'ta': ['‡Æ®‡Æ©‡Øç‡Æ±‡Æø', '‡Æ™‡Øã‡Æ§‡ØÅ‡ÆÆ‡Øç', '‡Æµ‡Øá‡Æ£‡Øç‡Æü‡Ææ‡ÆÆ‡Øç'],
        'te': ['‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å', '‡∞ö‡∞æ‡∞≤‡±Å', '‡∞µ‡∞¶‡±ç‡∞¶‡±Å'],
        'kn': ['‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å', '‡≤∏‡≤æ‡≤ï‡≥Å'],
        'mr': ['‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶', '‡§™‡•Å‡§∞‡•á', '‡§®‡§ï‡•ã'],
        'pa': ['‡®ß‡©∞‡®®‡®µ‡®æ‡®¶', '‡®¨‡®∏'],
        'bn': ['‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶', '‡¶•‡¶æ‡¶Æ‡ßÅ‡¶®'],
        'gu': ['‡™Ü‡™≠‡™æ‡™∞', '‡™¨‡™∏']
    }
    
    # Check # key press
    if digits == '#':
        logger.info("User pressed # to exit")
        return True
    
    # Check speech for exit keywords
    speech_lower = speech_result.lower()
    
    # Check language-specific keywords
    lang_keywords = exit_keywords.get(detected_lang, [])
    if any(keyword in speech_result or keyword.lower() in speech_lower for keyword in lang_keywords):
        logger.info(f"Exit keyword detected in {detected_lang}: {speech_result}")
        return True
    
    # Always check English keywords (fallback)
    if any(keyword in speech_lower for keyword in exit_keywords['en']):
        logger.info(f"Exit keyword detected (English): {speech_result}")
        return True
    
    return False


def end_conversation_route(call_sid: str, detected_lang: str) -> tuple:
    """
    End conversation gracefully with goodbye message.
    
    Args:
        call_sid: Twilio Call SID
        detected_lang: Language for goodbye message
        
    Returns:
        Tuple of (TwiML string, status code, headers)
    """
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    twilio_lang = get_twilio_lang(detected_lang)
    
    response = VoiceResponse()
    response.say(
        prompts["thank_you"],
        voice="Polly.Aditi",
        language=twilio_lang
    )
    response.hangup()
    
    # Get session before cleanup
    session = get_session(call_sid)
    caller_number = session.caller_number if session else None
    
    # Cleanup and get summary
    call_language_map.pop(call_sid, None)
    summary = end_session(call_sid)
    
    # Log conversation summary
    if summary:
        logger.info(f"Conversation summary for {call_sid}:\n{summary}")
        
        # Send WhatsApp summary in background (non-blocking)
        if caller_number:
            def send_whatsapp_background():
                try:
                    logger.info(f"Sending WhatsApp summary to {caller_number} in {detected_lang}")
                    success = send_summary_via_whatsapp(
                        caller_number=caller_number,
                        summary=summary,
                        language=detected_lang
                    )
                    if success:
                        logger.info(f"‚úÖ WhatsApp summary delivered to {caller_number}")
                    else:
                        logger.error(f"‚ùå Failed to send WhatsApp summary to {caller_number}")
                except Exception as e:
                    logger.error(f"Error sending WhatsApp summary: {e}", exc_info=True)
            
            # Send in background thread to not block call completion
            whatsapp_thread = threading.Thread(target=send_whatsapp_background)
            whatsapp_thread.daemon = True
            whatsapp_thread.start()
        else:
            logger.warning("No caller number available, cannot send WhatsApp summary")
    
    return str(response), 200, {'Content-Type': 'text/xml'}



@app.route("/health", methods=["GET"])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "pipeline_ready": pipeline is not None
    }), 200


@app.route("/voice/incoming", methods=["POST"])
def incoming_call():
    """
    Handle incoming Twilio voice calls.
    Detect caller's language from phone number and greet in their language.
    Initialize conversation session for multi-turn dialog.
    """
    logger.info("Incoming call received")
    
    # Get caller's phone number and Call SID
    caller_number = request.form.get('From', '')
    call_sid = request.form.get('CallSid', '')
    logger.info(f"Call from: {caller_number}, CallSid: {call_sid}")
    
    # Detect language from phone number
    detected_lang = detect_language_from_phone(caller_number)
    
    # Store language preference for this call
    call_language_map[call_sid] = detected_lang
    
    # Initialize conversation session
    create_session(call_sid, detected_lang, caller_number)
    logger.info(f"Created conversation session for {call_sid}")
    
    # Get prompts for detected language
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["en"])
    twilio_lang = get_twilio_lang(detected_lang)
    
    response = VoiceResponse()
    
    # Greet the caller in their language
    response.say(
        prompts["welcome"],
        voice="Polly.Aditi",  # Indian voice - supports multiple Indic languages
        language=twilio_lang
    )
    
    # Record the caller's question (first turn)
    # Enable transcription to bypass ElevenLabs STT (which is blocked at hackathon)
    response.record(
        max_length=30,
        action="/voice/process-turn",
        method="POST",
        play_beep=True,
        timeout=5,  # 5 seconds of silence ends recording
        transcribe=True,  # Use Twilio's transcription instead of ElevenLabs
        transcribe_callback="/voice/transcription-callback"  # Callback for transcription
    )
    
    logger.info(f"Sent TwiML in language '{detected_lang}' to record caller's question")
    return str(response), 200, {'Content-Type': 'text/xml'}


@app.route("/voice/transcription-callback", methods=["POST"])
def transcription_callback():
    """
    Handle Twilio's transcription callback.
    Store the transcription for use in the pipeline (bypasses ElevenLabs STT).
    """
    call_sid = request.form.get("CallSid")
    transcription_text = request.form.get("TranscriptionText", "")
    
    if call_sid and transcription_text:
        # Store Twilio's transcription for this call
        twilio_transcriptions[call_sid] = transcription_text
        logger.info(f"üìù Received Twilio transcription for {call_sid}: '{transcription_text}'")
    else:
        logger.warning(f"Incomplete transcription callback: CallSid={call_sid}, Text={transcription_text}")
    
    # Return empty response (Twilio doesn't expect TwiML from this endpoint)
    return "", 200


@app.route("/voice/process-turn", methods=["POST"])
def process_turn():
    """
    Process a conversation turn and prepare to continue the dialog.
    This endpoint handles each Q&A exchange in a continuous conversation.
    """
    recording_url = request.form.get("RecordingUrl")
    call_sid = request.form.get("CallSid")
    
    # Get language and session
    detected_lang = call_language_map.get(call_sid, "hi")
    session = get_session(call_sid)
    
    if not recording_url or not session:
        logger.warning(f"Missing recording URL or session for {call_sid}")
        return end_conversation_route(call_sid, detected_lang)
    
    logger.info(f"Processing turn {session.get_turn_count() + 1} for {call_sid}")
    
    # Process in background (reuse existing process_audio_background)
    import threading
    processing_thread = threading.Thread(
        target=process_audio_background,
        args=(recording_url, call_sid)
    )
    processing_thread.daemon = True
    processing_thread.start()
    
    # Return "processing" message and redirect to check response
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    twilio_lang = get_twilio_lang(detected_lang)
    
    response = VoiceResponse()
    response.say(prompts["processing"], voice="Polly.Aditi", language=twilio_lang)
    response.pause(length=2)
    
    # Redirect to check if response is ready
    base_url = request.url_root.rstrip('/')
    response.redirect(f"{base_url}/voice/check-response/{call_sid}", method="GET")
    
    return str(response), 200, {'Content-Type': 'text/xml'}


@app.route("/voice/check-response/<call_sid>", methods=["GET", "POST"])
def check_response_continuous(call_sid):
    """
    Check if AI response is ready, then play with barge-in capability.
    After playing response, ask if user has another question.
    """
    detected_lang = call_language_map.get(call_sid, "hi")
    session = get_session(call_sid)
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    twilio_lang = get_twilio_lang(detected_lang)
    
    response = VoiceResponse()
    output_path = OUTPUT_DIR / f"{call_sid}_response.wav"
    
    if not output_path.exists():
        # Still processing
        logger.info(f"Response not ready yet for {call_sid}")
        response.say(prompts["still_processing"], voice="Polly.Aditi", language=twilio_lang)
        response.pause(length=3)
        
        # Redirect back to check again
        base_url = request.url_root.rstrip('/')
        response.redirect(f"{base_url}/voice/check-response/{call_sid}", method="GET")
        return str(response), 200, {'Content-Type': 'text/xml'}
    
    # Response is ready! Play it with barge-in capability
    base_url = request.url_root.rstrip('/')
    audio_url = f"{base_url}/audio/{call_sid}_response.wav"
    logger.info(f"Playing response audio: {audio_url}")
    
    # Use Gather to enable barge-in interrupts
    gather = Gather(
        input='speech dtmf',  # Accept speech or DTMF
        action=f'/voice/handle-interrupt/{call_sid}',
        method='POST',
        timeout=30,  # Wait 30 seconds for user to ask next question
        speech_timeout='auto',  # Auto-detect end of speech
        hints='yes,no,bye,thank you,goodbye,okay,‡§π‡§æ‡§Å,‡§®‡§π‡•Ä‡§Ç,‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶',  # Speech hints
        language=twilio_lang,
        barge_in=True  # ‚≠ê INTERRUPT CAPABILITY - stops audio when user speaks
    )
    
    # Play the AI response
    gather.play(audio_url)
    
    # After audio, ask for next question
    gather.say(
        prompts.get("another_question", "Do you have another question?"),
        voice="Polly.Aditi",
        language=twilio_lang
    )
    
    response.append(gather)
    
    # If no input after gather, redirect to prompt again
    base_url = request.url_root.rstrip('/')
    response.redirect(f"{base_url}/voice/prompt-next/{call_sid}", method="GET")
    
    return str(response), 200, {'Content-Type': 'text/xml'}


@app.route("/voice/handle-interrupt/<call_sid>", methods=["POST"])
def handle_interrupt(call_sid):
    """
    Handle user interrupt or continuation.
    Check for exit intent or continue to next question.
    """
    speech_result = request.form.get("SpeechResult", "")
    digits = request.form.get("Digits", "")
    
    detected_lang = call_language_map.get(call_sid, "hi")
    session = get_session(call_sid)
    
    logger.info(f"Handle interrupt - Speech: '{speech_result}', Digits: '{digits}'")
    
    # Store Twilio's transcription (much better than ElevenLabs for follow-ups!)
    if speech_result and len(speech_result.strip()) > 0:
        twilio_transcriptions[call_sid] = speech_result
        logger.info(f"Stored Twilio transcription for {call_sid}: '{speech_result}'")
    
    # Check for exit intent
    if check_exit_intent(speech_result.lower(), digits, detected_lang):
        logger.info(f"User wants to exit conversation {call_sid}")
        return end_conversation_route(call_sid, detected_lang)
    
    # Check if max turns or time limit reached
    if session and session.should_end():
        logger.info(f"Session limits reached for {call_sid}")
        return end_conversation_route(call_sid, detected_lang)
    
    # Continue conversation - record next question
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    twilio_lang = get_twilio_lang(detected_lang)
    
    response = VoiceResponse()
    
    # Record next question
    response.record(
        max_length=30,
        action="/voice/process-turn",  # Loop back to process turn
        method="POST",
        play_beep=False,  # No beep for continuation
        timeout=5,
        transcribe=True,  # Enable Twilio transcription
        transcribe_callback="/voice/transcription-callback"
    )
    
    return str(response), 200, {'Content-Type': 'text/xml'}


@app.route("/voice/prompt-next/<call_sid>", methods=["GET", "POST"])
def prompt_next(call_sid):
    """
    Prompt user for next question after silence.
    This is called if user didn't respond after the "another question?" prompt.
    """
    detected_lang = call_language_map.get(call_sid, "hi")
    session = get_session(call_sid)
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    twilio_lang = get_twilio_lang(detected_lang)
    
    logger.info(f"Prompting for next question  - {call_sid}")
    
    # If limits reached or no session, end gracefully
    if not session or session.should_end():
        logger.info(f"Ending conversation after timeout - {call_sid}")
        return end_conversation_route(call_sid, detected_lang)
    
    response = VoiceResponse()
    
    # Gather with speech for next question
    gather = Gather(
        input='speech dtmf',
        action=f'/voice/handle-interrupt/{call_sid}',
        method='POST',
        timeout=10,  # 10 seconds of silence
        speech_timeout='auto',
        hints='yes,no,bye,thank you',
        language=twilio_lang
    )
    
    gather.say(
        prompts.get("still_there", "Are you still there? Do you have another question?"),
        voice="Polly.Aditi",
        language=twilio_lang
    )
    
    response.append(gather)
    
    # After timeout, end call
    logger.info(f"No response after second prompt, ending {call_sid}")
    return end_conversation_route(call_sid, detected_lang)





@app.route("/voice/recording", methods=["POST"])
def handle_recording():
    """
    Handle the recorded audio from Twilio.
    Immediately return TwiML with hold message, then process in background.
    """
    logger.info("Recording received from Twilio")
    
    # Get recording URL from Twilio
    recording_url = request.form.get("RecordingUrl")
    call_sid = request.form.get("CallSid")
    
    # Get stored language for this call (default to Hindi)
    detected_lang = call_language_map.get(call_sid, "hi")
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    
    twilio_lang_map = {
        "hi": "hi-IN", "ta": "ta-IN", "te": "te-IN", "kn": "kn-IN",
        "mr": "mr-IN", "pa": "pa-IN", "bn": "bn-IN", "gu": "gu-IN", "en": "en-IN"
    }
    twilio_lang = twilio_lang_map.get(detected_lang, "hi-IN")
    
    if not recording_url:
        logger.error("No recording URL provided")
        response = VoiceResponse()
        response.say(prompts["error"], voice="Polly.Aditi", language=twilio_lang)
        return str(response), 200, {'Content-Type': 'text/xml'}
    
    logger.info(f"Call SID: {call_sid}")
    logger.info(f"Recording URL: {recording_url}")
    
    response = VoiceResponse()
    
    # Check if pipeline is ready
    if pipeline is None:
        logger.error("Pipeline not initialized")
        response.say(prompts["error"], voice="Polly.Aditi", language=twilio_lang)
        return str(response), 200, {'Content-Type': 'text/xml'}
    
    # IMMEDIATELY start processing in background (don't wait)
    import threading
    processing_thread = threading.Thread(
        target=process_audio_background,
        args=(recording_url, call_sid)
    )
    processing_thread.daemon = True
    processing_thread.start()
    
    # Return TwiML immediately with hold message in caller's language
    response.say(
        prompts["processing"],
        voice="Polly.Aditi",
        language=twilio_lang
    )
    
    # Use pause instead of music for faster polling
    # Pause for 5 seconds, then check if response is ready
    response.pause(length=5)
    
    # Redirect to check if processing is done (will check every 5 seconds)
    # Use absolute URL for Twilio redirect to work properly
    base_url = request.url_root.rstrip('/')
    response.redirect(f"{base_url}/voice/get-response/{call_sid}", method="GET")
    
    return str(response), 200, {'Content-Type': 'text/xml'}


def process_audio_background(recording_url: str, call_sid: str):
    """Process audio in background thread with conversation context"""
    try:
        logger.info("Background processing started for " + call_sid)
        
        # Get phone-detected language for this call (if available)
        phone_detected_lang = call_language_map.get(call_sid, "hi")
        logger.info(f"Phone-detected language for {call_sid}: {phone_detected_lang}")
        
        # Get conversation session for context
        session = get_session(call_sid)
        conversation_history = []
        
        if session:
            # Build conversation history from previous turns
            for turn in session.turns:
                conversation_history.append({
                    'question': turn.question,
                    'answer': turn.answer
                })
            logger.info(f"Retrieved {len(conversation_history)} previous turns for context")
        
        # Download the recording
        logger.info("Downloading recording from Twilio...")
        audio_data = download_twilio_recording(recording_url)
        
        # Save to temp file
        input_audio_path = TEMP_DIR / f"{call_sid}_input.wav"
        with open(input_audio_path, "wb") as f:
            f.write(audio_data)
        logger.info(f"Recording saved to {input_audio_path}")
        
        # Check if we have Twilio's transcription (from Gather - much better quality!)
        twilio_transcription = twilio_transcriptions.pop(call_sid, None)
        if twilio_transcription:
            logger.info(f"Using Twilio's transcription: '{twilio_transcription}'")
        
        # Process through pipeline with phone language hint AND conversation history
        logger.info("Processing through AI pipeline...")
        result = pipeline.process_audio(
            audio_path=str(input_audio_path),
            source_lang="auto",
            target_lang="en",
            phone_detected_lang=phone_detected_lang,  # Pass language hint from phone
            conversation_history=conversation_history,  # Pass conversation context
            pre_transcribed_text=twilio_transcription  # Use Twilio's transcription if available!
        )
        
        # Save output audio
        output_audio_path = OUTPUT_DIR / f"{call_sid}_response.wav"
        with open(output_audio_path, "wb") as f:
            f.write(result.output_audio_bytes)
        logger.info(f"Response saved to {output_audio_path}")
        
        # Store this Q&A turn in the conversation session (only if transcription valid)
        # IMPORTANT: Store ENGLISH versions so LLM sees English context and responds in English!
        if session and result.is_valid_transcription:
            session.add_turn(
                question=result.translated_query or result.transcribed_text,  # English question
                answer=result.llm_response_en  # English answer
            )
            logger.info(f"Stored turn #{session.get_turn_count()} in conversation session (English versions)")
        elif session and not result.is_valid_transcription:
            logger.warning(f"Skipped storing turn due to invalid transcription - asked user to repeat")
        
        # Clean up temp file
        input_audio_path.unlink(missing_ok=True)
        
        logger.info(f"Background processing complete for {call_sid}")
        
    except Exception as e:
        logger.error(f"Error in background processing: {e}", exc_info=True)


@app.route("/voice/get-response/<call_sid>", methods=["GET", "POST"])
def get_response(call_sid):
    """Check if response is ready and play it"""
    response = VoiceResponse()
    
    # Get stored language for this call (default to Hindi)
    detected_lang = call_language_map.get(call_sid, "hi")
    prompts = LANGUAGE_PROMPTS.get(detected_lang, LANGUAGE_PROMPTS["hi"])
    
    twilio_lang_map = {
        "hi": "hi-IN", "ta": "ta-IN", "te": "te-IN", "kn": "kn-IN",
        "mr": "mr-IN", "pa": "pa-IN", "bn": "bn-IN", "gu": "gu-IN", "en": "en-IN"
    }
    twilio_lang = twilio_lang_map.get(detected_lang, "hi-IN")
    
    # Check if response audio exists
    output_audio_path = OUTPUT_DIR / f"{call_sid}_response.wav"
    
    if output_audio_path.exists():
        # Response is ready! Play it
        base_url = request.url_root.rstrip('/')
        audio_url = f"{base_url}/audio/{call_sid}_response.wav"
        
        logger.info(f"Playing response audio: {audio_url}")
        response.play(audio_url)
        
        # Thank you message in caller's language
        response.say(
            prompts["thank_you"],
            voice="Polly.Aditi",
            language=twilio_lang
        )
        
        # Clean up language mapping for this call
        call_language_map.pop(call_sid, None)
    else:
        # Still processing, pause and check again
        logger.info(f"Response not ready yet for {call_sid}, continuing to wait")
        
        # Status message in caller's language
        response.say(
            prompts["still_processing"],
            voice="Polly.Aditi",
            language=twilio_lang
        )
        # Pause for 5 seconds then check again
        response.pause(length=5)
        # Use absolute URL for redirect
        base_url = request.url_root.rstrip('/')
        response.redirect(f"{base_url}/voice/get-response/{call_sid}", method="GET")
    
    twiml_str = str(response)
    logger.info(f"Returning TwiML: {twiml_str[:200]}...")  # Log first 200 chars
    return twiml_str, 200, {'Content-Type': 'text/xml'}


@app.route("/audio/<filename>", methods=["GET"])
def serve_audio(filename):
    """Serve audio files for Twilio to play"""
    try:
        audio_path = OUTPUT_DIR / filename
        if not audio_path.exists():
            logger.error(f"Audio file not found: {filename}")
            return "File not found", 404
        
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        
        # ElevenLabs returns MP3 format despite .wav extension
        # Set correct Content-Type for Twilio
        return audio_data, 200, {
            'Content-Type': 'audio/mpeg',
            'Content-Disposition': f'inline; filename="{filename}"'
        }
    except Exception as e:
        logger.error(f"Error serving audio: {e}")
        return "Error serving file", 500


def download_twilio_recording(recording_url: str) -> bytes:
    """Download audio recording from Twilio"""
    # Twilio recordings require authentication
    # Add .wav to get WAV format instead of MP3
    wav_url = f"{recording_url}.wav"
    
    response = requests.get(
        wav_url,
        auth=(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN),
        timeout=30
    )
    response.raise_for_status()
    
    return response.content


if __name__ == "__main__":
    # Check required environment variables
    if not all([TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN]):
        logger.error("Missing Twilio credentials. Please set TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN")
        exit(1)
    
    logger.info("Starting Agrow Twilio Server...")
    logger.info(f"Twilio Phone Number: {TWILIO_PHONE_NUMBER or 'Not set'}")
    
    # Run Flask app
    # For production, use a proper WSGI server like gunicorn
    app.run(
        host="0.0.0.0",
        port=5001,
        debug=True
    )
